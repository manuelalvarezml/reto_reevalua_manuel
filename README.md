# ğŸ¦ ClasificaciÃ³n de Riesgo Crediticio con SageMaker + Bedrock

Este proyecto combina modelos generativos (Amazon Bedrock) con machine learning tradicional para predecir riesgo crediticio. Se generan descripciones (`description`) y etiquetas (`target`) con GenAI y se entrena un modelo en SageMaker (Logistic Regression) para inferir riesgo de crÃ©dito.

---

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ artifacts/                      # Preprocesadores guardados (OneHotEncoder)
â”œâ”€â”€ downloaded_artifacts/          # Artifacts descargados del modelo entrenado
â”œâ”€â”€ data_files/                    # Dataset original + columnas generadas (description, target)
â”œâ”€â”€ bedrock_test_files/            # Pruebas para conexiÃ³n y modelos disponibles de Bedrock
â”œâ”€â”€ train_data_sagemaker.csv       # Datos de entrenamiento listos para SageMaker
â”œâ”€â”€ test_data_sagemaker.csv        # Datos de test para evaluaciÃ³n
â”œâ”€â”€ y_test_true_labels.csv         # Etiquetas verdaderas para el test
â”œâ”€â”€ test_data_for_inference.csv    # Archivo de prueba para hacer inferencia en el endpoint
â”œâ”€â”€ eda_credit_risk.ipynb          # ExploraciÃ³n de datos (EDA)
â”œâ”€â”€ generate_descriptions.py       # Usa Bedrock para crear la columna 'description'
â”œâ”€â”€ generate_risk_targets.py       # Usa Bedrock para generar la columna 'target' (good/bad risk)
â”œâ”€â”€ preprocess_for_sagemaker.py    # Preprocesa y guarda archivos para SageMaker (OneHot)
â”œâ”€â”€ train_logreg_sagemaker.py      # Entrena regresiÃ³n logÃ­stica con sklearn en la nube
â”œâ”€â”€ deploy_model_sagemaker.py      # Despliega el endpoint en SageMaker
â”œâ”€â”€ invoke_endpoint.py             # Realiza inferencia en el endpoint
```

---

## âš™ï¸ Flujo del pipeline (Logistic Regression)

1. **Preprocesamiento:**

   ```bash
   python preprocess_for_sagemaker.py
   ```

   Genera:

   - `train_data_sagemaker.csv`, `test_data_sagemaker.csv`, `y_test_true_labels.csv`
   - `artifacts/tabular_preprocessor.joblib`

2. **Subida a S3:**

   ```bash
   python upload_dataset_to_s3.py
   ```

3. **Entrenamiento:**

   ```bash
   python train_logreg_sagemaker.py
   ```

4. **Descarga artifacts del job:**

   - Actualiza `job_name` en `download_artifacts_logreg_training.py`

   ```bash
   python download_artifacts_logreg_training.py
   ```

5. **Empaquetado para despliegue:**

   ```bash
   cp artifacts/tabular_preprocessor.joblib downloaded_artifacts/
   cd downloaded_artifacts
   tar -czf model.tar.gz model.joblib train_logreg.py tabular_preprocessor.joblib
   ```

6. **Despliegue del modelo:**

   ```bash
   python upload_model_to_s3_for_deployment.py
   python deploy_model_sagemaker.py
   ```

7. **Inferencia:**
   ```bash
   python invoke_endpoint.py
   ```

---

## ğŸ“Š Resultados

Se entrenÃ³ un modelo de regresiÃ³n logÃ­stica con `class_weight="balanced"` para mitigar el desbalance de clases. Esto mejorÃ³ considerablemente el recall en los casos de **alto riesgo** (de 32.6% a 76.1%) a cambio de una leve caÃ­da en accuracy.

**MÃ©tricas:**

- Accuracy: 70%
- Recall (bad risk): **76.1%**
- Precision (good risk): 90.5%
- ROC AUC: **0.7974**

ğŸ“Œ Se prioriza **minimizar falsos negativos en riesgos malos** (i.e. no dar prÃ©stamos a quien no debe).

---

## ğŸ§ª Inferencia de prueba

Se probÃ³ con 15 casos:

- 5 de **riesgo alto obvio** â†’ correctamente clasificados como 0
- 5 de **riesgo bajo obvio** â†’ correctamente clasificados como 1
- 5 mixtos â†’ desempeÃ±o razonable

âœ… El modelo predice correctamente segÃºn el objetivo del negocio: protegerse ante perfiles de alto riesgo.

---

## âœ… Requisitos

- Python 3.8
- `scikit-learn` entre **1.0 y 1.2** (lÃ­mite actual en SageMaker: [ver documentaciÃ³n oficial](https://docs.aws.amazon.com/sagemaker/latest/dg/sklearn.html))
- AWS CLI + permisos para usar:
  - Amazon SageMaker
  - Amazon Bedrock (activado)
